{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03a - CNN Fine-Tuning (Run 6a)\n",
    "Fine-tune ResNet-18 layer4 as a per-frame classifier on Drive&Act Kinect IR.\n",
    "\n",
    "**Pipeline:** Fine-tune CNN -> Re-extract features -> Train LSTM (notebook 03)\n",
    "\n",
    "**Runtime:** GPU required. ~2-5 min/epoch, ~15 epochs max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Setup\n",
    "import os\n",
    "IN_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    REPO_DIR = '/content/Driver-Activity-Recognition'\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        !git clone https://github.com/batuhne/Driver-Activity-Recognition.git {REPO_DIR}\n",
    "\n",
    "    os.chdir(REPO_DIR)\n",
    "    !pip install -q -r requirements.txt\n",
    "    DATA_ROOT = '/content/drive/MyDrive/DriveAndAct'\n",
    "else:\n",
    "    DATA_ROOT = './data'\n",
    "\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "print(f'Data root: {DATA_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.utils import load_config\n",
    "from src.cnn_finetune import finetune_cnn\n",
    "\n",
    "config = load_config()\n",
    "if IN_COLAB:\n",
    "    config['data']['root'] = DATA_ROOT\n",
    "    drive_output = os.path.join(DATA_ROOT, 'results')\n",
    "    config['output']['checkpoint_dir'] = os.path.join(drive_output, 'checkpoints')\n",
    "    config['output']['log_dir'] = os.path.join(drive_output, 'logs')\n",
    "    config['output']['figure_dir'] = os.path.join(drive_output, 'figures')\n",
    "\n",
    "# ==================== Run 6a: CNN Fine-Tuning Config ====================\n",
    "config['model']['freeze_mode'] = 'layer4'       # Only layer4 trainable\n",
    "\n",
    "config['cnn_finetune'] = {\n",
    "    'batch_size': 64,              # Single frames, can use larger batch\n",
    "    'epochs': 15,\n",
    "    'early_stop_patience': 7,\n",
    "    'cnn_lr': 1e-4,               # CNN layer4 LR\n",
    "    'fc_lr': 1e-3,                # Classifier head LR\n",
    "    'weight_decay': 1e-4,\n",
    "    'label_smoothing': 0.1,\n",
    "    'gradient_clip': 1.0,\n",
    "    'use_amp': True,\n",
    "    'use_weighted_sampler': True,  # EN sampler for class balance\n",
    "}\n",
    "config['training']['en_beta'] = 0.99\n",
    "config['training']['num_workers'] = 2\n",
    "\n",
    "print(f'GPU available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "print(f\"\\n--- CNN Fine-Tuning Config ---\")\n",
    "print(f\"freeze_mode: {config['model']['freeze_mode']}\")\n",
    "print(f\"batch_size: {config['cnn_finetune']['batch_size']}\")\n",
    "print(f\"CNN LR: {config['cnn_finetune']['cnn_lr']}, FC LR: {config['cnn_finetune']['fc_lr']}\")\n",
    "print(f\"epochs: {config['cnn_finetune']['epochs']}, patience: {config['cnn_finetune']['early_stop_patience']}\")\n",
    "print(f\"AMP: {config['cnn_finetune']['use_amp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics: verify model structure\n",
    "from src.cnn_finetune import CNNClassifier\n",
    "\n",
    "model_check = CNNClassifier(num_classes=34, freeze_mode=config['model']['freeze_mode'])\n",
    "total = sum(p.numel() for p in model_check.parameters())\n",
    "trainable = sum(p.numel() for p in model_check.parameters() if p.requires_grad)\n",
    "print(f'Total params: {total:,}')\n",
    "print(f'Trainable params: {trainable:,}')\n",
    "print(f'Frozen params: {total - trainable:,}')\n",
    "print()\n",
    "for idx, (name, child) in enumerate(model_check.backbone.features.named_children()):\n",
    "    cp = sum(p.numel() for p in child.parameters())\n",
    "    ct = sum(p.numel() for p in child.parameters() if p.requires_grad)\n",
    "    if cp > 0:\n",
    "        status = 'TRAINABLE' if ct > 0 else 'frozen'\n",
    "        print(f'  [{idx}] {name:>2}: {cp:>10,} params  [{status}]')\n",
    "del model_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CNN fine-tuning\n",
    "best_checkpoint = finetune_cnn(config)\n",
    "print(f'\\nBest checkpoint saved to: {best_checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory summary\n",
    "if torch.cuda.is_available():\n",
    "    peak_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f'GPU peak memory: {peak_mem:.2f} GB / {total_mem:.1f} GB ({peak_mem/total_mem*100:.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-extract Features with Fine-Tuned CNN\n",
    "Now re-run feature extraction using the fine-tuned backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_extract import extract_features\n",
    "\n",
    "# Use fine-tuned features directory (don't overwrite original)\n",
    "config['features']['save_dir'] = 'features_finetuned'\n",
    "config['features']['dtype'] = 'float32'\n",
    "\n",
    "# Path to fine-tuned CNN checkpoint\n",
    "cnn_checkpoint = os.path.join(config['output']['checkpoint_dir'], 'cnn_finetuned.pth')\n",
    "print(f'CNN checkpoint: {cnn_checkpoint}')\n",
    "print(f'Output dir: {os.path.join(config[\"data\"][\"root\"], config[\"features\"][\"save_dir\"])}')\n",
    "\n",
    "extract_features(config, cnn_checkpoint=cnn_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify re-extracted features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_dir = os.path.join(config['data']['root'], config['features']['save_dir'])\n",
    "for split in ['train', 'val', 'test']:\n",
    "    manifest = pd.read_csv(os.path.join(feature_dir, split, 'manifest.csv'))\n",
    "    sample_path = os.path.join(feature_dir, split, manifest.iloc[0]['filename'])\n",
    "    sample = np.load(sample_path)\n",
    "    print(f'{split}: {len(manifest)} segments, shape={sample.shape}, dtype={sample.dtype}')\n",
    "\n",
    "print(f'\\nFeatures saved to: {feature_dir}')\n",
    "print('Now run notebook 03 (LSTM training) with features_dir = features_finetuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
