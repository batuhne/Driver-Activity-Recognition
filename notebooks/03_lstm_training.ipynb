{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 - LSTM Training (Run 6a)\nTrain ActivityLSTM on fine-tuned ResNet-18 features.\n\n**Pre-requisite:** Run notebook 03a first to fine-tune CNN and re-extract features.\n\n**Runtime:** GPU recommended for faster training."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Colab Setup\nimport os\nIN_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n\nif IN_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n\n    REPO_DIR = '/content/Driver-Activity-Recognition'\n    if not os.path.exists(REPO_DIR):\n        !git clone https://github.com/batuhne/Driver-Activity-Recognition.git {REPO_DIR}\n\n    os.chdir(REPO_DIR)\n    !pip install -q -r requirements.txt\n    DATA_ROOT = '/content/drive/MyDrive/DriveAndAct'\nelse:\n    DATA_ROOT = './data'\n\nprint(f'Working directory: {os.getcwd()}')\nprint(f'Data root: {DATA_ROOT}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom src.utils import load_config, set_seed\nfrom src.train import train\n\nconfig = load_config()\nif IN_COLAB:\n    config['data']['root'] = DATA_ROOT\n    # Save outputs to Drive so they persist between sessions\n    drive_output = os.path.join(DATA_ROOT, 'results')\n    config['output']['checkpoint_dir'] = os.path.join(drive_output, 'checkpoints')\n    config['output']['log_dir'] = os.path.join(drive_output, 'logs')\n    config['output']['figure_dir'] = os.path.join(drive_output, 'figures')\n\n# ==================== Run 6a: LSTM on Fine-Tuned Features ====================\n# Use features_finetuned (from notebook 03a) instead of original frozen features.\n# All LSTM hyperparams match Run 3 (best MPCA=39.2%).\n\nconfig['features']['save_dir'] = 'features_finetuned'  # KEY: use fine-tuned features\n\n# Training mode: feature-based (fast, no video I/O)\nconfig['training']['mode'] = 'feature_based'\n\n# Model config — same as Run 3\nconfig['model']['use_layernorm'] = True\nconfig['model']['bidirectional'] = True\nconfig['model']['pooling'] = 'attention'\nconfig['model']['lstm_hidden'] = 256            # Run 3 value\nconfig['model']['lstm_dropout'] = 0.3           # Run 3 value\n\n# Training config — Run 3 values\nconfig['training']['batch_size'] = 32\nconfig['training']['lr'] = 0.001                # Run 3 LR\nconfig['training']['loss_type'] = 'ce'\nconfig['training']['label_smoothing'] = 0.1\nconfig['training']['mixup_alpha'] = 0.0         # Keep simple\nconfig['training']['noise_std'] = 0.0\nconfig['training']['weight_decay'] = 0.0001     # Run 3 value\nconfig['training']['epochs'] = 50\nconfig['training']['early_stop_patience'] = 12\nconfig['training']['scheduler_type'] = 'plateau'\nconfig['training']['scheduler_factor'] = 0.5\nconfig['training']['scheduler_patience'] = 5\nconfig['training']['gradient_clip'] = 1.0\nconfig['training']['use_weighted_sampler'] = True   # Run 3 value\nconfig['training']['en_beta'] = 0.99                # Run 3 value\nconfig['training']['num_workers'] = 2               # Colab compatible\n\nprint(f'GPU available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\nprint(f\"\\n--- Run 6a LSTM Config ---\")\nprint(f\"Features: {config['features']['save_dir']}\")\nprint(f\"Mode: {config['training']['mode']}\")\nprint(f\"LSTM: h={config['model']['lstm_hidden']}, BiLSTM={config['model']['bidirectional']}, pool={config['model']['pooling']}\")\nprint(f\"LR: {config['training']['lr']}, batch={config['training']['batch_size']}\")\nprint(f\"Sampler: {'WeightedRandom' if config['training']['use_weighted_sampler'] else 'DISABLED'}\")"
  },
  {
   "cell_type": "code",
   "source": "# Run 6a Diagnostics: verify fine-tuned features exist and model size\nimport csv\nimport numpy as np\nfrom src.utils import compute_effective_number_weights\nfrom src.models import ActivityLSTM\n\n# Check features directory\nfeature_dir = os.path.join(config['data']['root'], config['features']['save_dir'])\nmanifest_path = os.path.join(feature_dir, 'train', 'manifest.csv')\n\nif not os.path.exists(manifest_path):\n    print(f\"ERROR: {manifest_path} not found!\")\n    print(\"Run notebook 03a first to fine-tune CNN and re-extract features.\")\nelse:\n    labels = []\n    with open(manifest_path) as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            labels.append(int(row['label']))\n\n    num_classes = max(labels) + 1\n    print(f\"Features dir: {feature_dir}\")\n    print(f\"Training samples: {len(labels)}, Unique classes: {len(set(labels))}, num_classes: {num_classes}\")\n\n    # Check a sample feature shape\n    sample = np.load(os.path.join(feature_dir, 'train', 'seg_000000.npy'))\n    print(f\"Feature shape: {sample.shape}, dtype: {sample.dtype}\")\n\n    # Model param count\n    model_check = ActivityLSTM(\n        input_dim=config['model']['feature_dim'],\n        hidden_dim=config['model']['lstm_hidden'],\n        num_layers=config['model']['lstm_layers'],\n        num_classes=num_classes,\n        lstm_dropout=config['model']['lstm_dropout'],\n        fc_dropout=config['model']['fc_dropout'],\n        use_layernorm=config['model'].get('use_layernorm', False),\n        bidirectional=config['model'].get('bidirectional', False),\n        pooling=config['model'].get('pooling', 'last'),\n    )\n    total_params = sum(p.numel() for p in model_check.parameters())\n    print(f\"\\nLSTM params: {total_params:,}\")\n    del model_check",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# GPU memory summary (run after training)\nif torch.cuda.is_available():\n    peak_mem = torch.cuda.max_memory_allocated() / 1024**3\n    current_mem = torch.cuda.memory_allocated() / 1024**3\n    total_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"GPU Memory: peak={peak_mem:.2f} GB, current={current_mem:.2f} GB, total={total_mem:.1f} GB\")\n    print(f\"Utilization: {peak_mem/total_mem*100:.0f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Training\n",
    "Launch TensorBoard to monitor training progress in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TensorBoard (works in Colab and Jupyter)\n%load_ext tensorboard\n%tensorboard --logdir {config['output']['log_dir']}"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}